---
permalink: /
# title: "About Me"
# excerpt: "About me"
author_profile: true
redirect_from: 
  - /home/
  - /home.html
---

{% include base_path %}

# Min-Jae Hwang
I am currently a Research Scientist at [Meta AI](https://ai.facebook.com/).
Prior to Meta AI, I was a research scientist at [Naver Corporation](https://www.navercorp.com/en).
I received my Ph.D. degree in department of Electrical and Electronics at [Yonsei University](https://www.yonsei.ac.kr/en_sc/index.jsp).
During my Ph.D. course, I was fortunate to have research experiences as an intern at [Microsoft Research Asia](https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/) and [Naver Corporation](https://www.navercorp.com/en).

My research interests include [Text-to-Speech (TTS)](https://www.ncloud.com/product/aiService/css) and [Speech-to-Speech Translation (S2ST)](https://ai.facebook.com/blog/teaching-ai-to-translate-100s-of-spoken-and-written-languages-in-real-time/).
Specifically, my research history focuses on improving performance of neural vocoder for TTS systems.
At Meta, I extended my research field to the expressive S2ST, which preserves source speech's paralinguistic characteristics during speech translation process.

I'm open to learn new knowledge and enjoy applying them to solve our society's real-world problems.
If you are interested in me, feel free to [contact me]({{ base_path }}/contacts.html).

<small><i class="fa fa-download" aria-hidden="true"></i> Download my [CV]({{base_path}}/files/cv/cv_latest.pdf)</small>

**<span style="color:green">NEWS!</span>**  
:heavy_check_mark: 5/2024 : I joined [Meta AI, Seattle, USA](https://ai.facebook.com/) as Research Scientist!
<br>
:heavy_check_mark: 2/2024 : I gave guest lectures at [BishBash 2024 event]({{base_path}}/files/slides/2402_bish_bash.pdf) for the topic of expressive S2ST.
<br>
:heavy_check_mark: 11/2023 : We launched [Seamless](https://ai.meta.com/research/seamless-communication/), a new family of AI translation models that preserve expression and deliver near-real time streaming translations.
<br>
:heavy_check_mark: 11/2023 : SeamlessM4T was recognized by [TIME magazine](https://time.com/collection/best-inventions-2023/6326994/meta-seamlessm4t/) among the best inventions of 2023!
<br>
:heavy_check_mark: 8/2023 : We launched [SeamlessM4T](https://ai.meta.com/blog/seamless-m4t/), a foundational multilingual and multitask model that seamlessly translates and transcribes across speech and text.
<!-- <br>
:heavy_check_mark: 9/2022 : Our paper<sup>[1](https://nips.cc/Conferences/2022/Schedule?showEvent=54658)</sup> has been accepted to [NeurIPS 2022](https://nips.cc/). -->
<!-- <br> -->
<!-- :heavy_check_mark: 6/2022 : I\'ll join [Meta AI, Seattle, USA](https://ai.facebook.com/) as a Postdoctoral Researcher for this October! -->
<!-- <br> -->
<!-- :heavy_check_mark: 5/2022 : Our two papers<sup>[1](https://arxiv.org/abs/2206.14984), [2](https://arxiv.org/abs/2206.15067)</sup> have been accepted to [Interspeech 2022](https://interspeech2022.org/). -->
<!-- <br> -->
<!-- :heavy_check_mark: 5/2022 : I gave guest lectures at [KAIST](https://www.kaist.ac.kr/en/) and [SNU](https://en.snu.ac.kr/) (Topic : Voice Synthesis and Applications). -->
<!-- <br> -->
<!-- :heavy_check_mark: 1/2022 : Our two papers<sup>[1](https://ieeexplore.ieee.org/abstract/document/9748515), [2](https://ieeexplore.ieee.org/abstract/document/9748530/)</sup> have been aceepted to [ICEIC 2022](https://iceic.org/2022/). -->
{: .notice--primary}

<!-- {: .notice} -->

***
# Research Interests
- **Speech-to-speech translation (S2ST)**
  - <small>Expressive S2ST system</small>
- **Text-to-speech (TTS) synthesis**
  - <small>High-quality and real-time waveform generation method</small>
  - <small>Expressive and emotional TTS system</small>

***
# Recent Publications
- [Seamless: Multilingual Expressive and Streaming Speech Translation](https://ai.meta.com/research/publications/seamless-multilingual-expressive-and-streaming-speech-translation/)  
  <small>Team Seamless Communication</small>

- [SeamlessM4Tâ€”Massively Multilingual & Multimodal Machine Translation](https://ai.meta.com/research/publications/seamlessm4t-massively-multilingual-multimodal-machine-translation/)  
  <small>Team Seamless Communication</small>

- [HierSpeech: Bridging the Gap between Text and Speech by Hierarchical Variational Inference using Self-supervised Representations for Speech Synthesis](https://nips.cc/Conferences/2022/Schedule?showEvent=54658)  
  <small>Sang-Hoon Lee, Seung-Bin Kim, Ji-Hyun Lee, Eunwoo Song, __Min-Jae Hwang__, Seong-Whan Lee</small>  
  <small>Accepted to [NeurIPS 2022](https://nips.cc/)</small>  

- [Language Model-Based Emotion Prediction Methods for Emotional Speech Synthesis Systems](https://arxiv.org/abs/2206.15067)  
  <small>Hyun-Wook Yoon, Ohsung Kwon, Hoyeon Lee, Ryuichi Yamamoto, Eunwoo Song, Jae-Min Kim, __Min-Jae Hwang__</small>  
  <small>Accepted to [Interspeech 2022](https://interspeech2022.org/)</small>  

- [TTS-by-TTS 2: Data-selective Augmentation for Neural Speech Synthesis using Ranking Support Vector Machine with Variational Autoencoder](https://arxiv.org/abs/2206.14984)  
  <small>Eunwoo Song, Ryuichi Yamamoto, Ohsung Kwon, Chan-Ho Song, __Min-Jae Hwang__, Suhyeon Oh, Hyun-Wook Yoon, Jin-Seob Kim, Jae-Min Kim</small>  
  <small>Accepted to [Interspeech 2022](https://interspeech2022.org/)</small>  

  <small>[[See more]]({{ base_path }}/publications/)</small>

***
[![Hits](https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fmjhwang93.github.io&count_bg=%2364C83D&title_bg=%23555555&icon=&icon_color=%23E7E7E7&title=hits&edge_flat=false)](https://hits.seeyoufarm.com)
